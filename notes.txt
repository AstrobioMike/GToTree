## next: 
    # working on fasta inputs
    # amino-acid inputs
    # hmm search
    # filtering hits
    # filtering genomes
    # alignments
    # concatenation and renaming
    # treeing
    # optional ko search
    # optional pfam search
    # implement nucleotide mode :(

conda create -n gtotree-dev -c astrobiomike -c conda-forge -c bioconda gtotree

conda activate gtotree-dev
conda install tqdm=4.67.1
conda install pyhmmer=0.11.0
conda install snakemake=8.30.0
pip install -e gtotree/

# example test
rm -rf gtotree-output/ ; gtotree2 -a ncbi-accessions.txt -H Universal -j 4

gtotree2 -a ncbi_accessions.txt -g genbank_files.txt -A amino_acid_files.txt -f fasta_files.txt -H Universal -j 4 -t -P

GToTree -a ncbi_accessions.txt -g genbank_files.txt -A amino_acid_files.txt -f fasta_files.txt -H Universal -j 4 -t -P -F

gtotree2 -a ncbi_accessions.txt -g GToTree-test-data/genbank_files.txt -f GToTree-test-data/fasta_files.txt -A GToTree-test-data/amino_acid_files.txt -j 4 -t -P

### OVERALL NOTES ###
# need a lot of testing on resume functionality
    # one thing i see happening is when i give ncbi accs and genbank files, on a second start it is still running some snakemake for ncbi
    # OH, i think that's happening because one failed 
    # it is not appropriately calculating how many it would do though (it's listing 2 instead of 1 job)
# need some check and handling if the input files changed when doing a resume
    # maybe just check and require they haven't changed at all, or a new run is needed
# when a resume is done, may want to just try snakemake workflows on inputs that failed the prior runs
# might not be using gnu parallel anymore due to snakemake files, so check that at the end
    # oh, add snakemake to definite citations
# since multiple logs may be created with --resume function, might need to add functionality to back up a log that exists to a sub-dir,
    # maybe with a time/date stamp of when first run appended to the name


### TO DO ###

# switch to only using http when available
    # affects:
        # get_ncbi_assembly_tables.py (DONE)
        # ncbi assembly downloads (DONE)
        # kofamscan data is only available via ftp (maybe host this somewhere else for GToTree)



### CHANGES ###

# default output changed to "gtotree-output"
# default lineage settings are D,P,C,S (no longer strain)
# http is used instead of ftp always where available (used to be ftp by default with http option)
# several output files and dirs had underscores changed to dashes (sorry, i now hate underscores when they're not necessary)
# estimated percent completion and redundancy are no long provided
    # (this was always just "free" info, but checkm2 is a much better way to do this, so i made the decision to stop providing it at all)
# --resume flag added (will be set automatically if the same output dir but no `-F` flag provided)
# taxids are no longer searched for in input genbank files, they will only be found/used for provided input ncbi-accessions
    # if this is actually a feature that benefitted anyone, i'll add it back in on request :)


### PLACES TO DEF IMPROVE ###
# right now i'm reading the target-ncbi-accession-info.tsv for every genome when doing the download (in processing_genomes.py)


### IMPROVEMENTS to highlight in paper ###

# python packaging and structure (rather than 4,000 lines of bash as main runner with dozens of individual python helper scripts)
# instead of just exiting and informing when input files have problems, GToTree2 fixes them
    # e.g., duplicate entries will be unique'd, windows line-endings will be converted, changes written to a new file that is then used
# snakemake control over the main components for easier restart capabilities
# things i've added over time
    # gtt-gen-SCG-HMMs
    # gtt-get-GTDB-accessions
    # gtt-subset...
    # new prepackaged HMMs based on GTDB taxonomy
    # in tandem scanning of target KOs or pfams, files for added vizualization in iToL

### """
# In its first 6 years, the original GToTree received over 500 citations and had tens of thousands of Conda installs. It has been
# successfully used and maintained over this time, despite its foundation being a main runner of ~4,000 lines of BASH and dozens of independent python
# and BASH helper scripts with a lot of redundancy in its code base. This was purely a consequence of my capabilities at the time.
### """
